参考 https://zhuanlan.zhihu.com/p/388206784
## Kafka使用注意事项
+ 配好特定的一个(或多个)topic
+ 一个唯一的group_id就是一套完整的数据，拉取的方式
+ 用earliest就是从头(未被删的)消费，用latest就是从当前末尾开始消费，或者自己定义每个partition从多少offset开始消费
+ Flink的source并行度可以设置为partition能整除的因子，比较均衡且没有悬空的线程

## 为什么需要 Kafka 中间件
+ Kafka是一个消息队列(MQ, Message Queue)
+ MQ的作用在于**解耦上下游业务**。即，上游只用管数据生产，而不必受制于下游的处理压力；下游只用管数据消费，只是订阅轮询topic，而不用依赖数据是怎么生产出来的；一次生产，可以多次消费(使用不同的group_id)
+ 相对于RabbitMq、Redis、Mysql等其他MQ，Kafka对大规模、实时(流式Flink/Spark)数据很友好，也是目前最流行的
+ 可持久化：当然是可持久化，不然那么大的数据堆在内存里放不下，redis也是可以定期持久化的

## 基本概念
+ Producer ：生产者，负责将消息发送到 Broker
+ Consumer ：消费者，从 Broker 接收消息。以group的形式去消费topic中的数据
+ Consumer Group ：消费者组，由多个 Consumer 组成。消费者组内每个消费者负责消费不同分区的数据，**一个分区只能由一个组内消费者消费**；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。
> 假设有5个partition，而flink消费开了6个线程，那么1个线程只能悬空。因为5个partition至多分给5个消费者线程
+ Broker ：中间人。可以看做一个独立的 Kafka 服务节点或 Kafka 服务实例。如果一台服务器上只部署了一个 Kafka 实例，那么我们也可以将 Broker 看做一台 Kafka 服务器。
+ Topic ：一个逻辑上的概念，包含很多 Partition，同一个 Topic 下的 Partiton 的消息内容是不相同的。
+ Partition ：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker 上，一个 topic 可以分为多个 分区，每个 partition 是一个有序的队列。 通过增加partition是可以扩容的。
> 分区占用文件句柄
+ Replica ：副本，同一分区的不同副本保存的是相同的消息，为保证集群中的某个节点发生故障时，该节点上的 partition 数据不丢失，且 kafka 仍然能够继续工作，kafka 提供了副本机制，一个 topic 的每个分区都有若干个副本，一个 leader 和若干个 follower。
+ Leader ：每个分区的多个副本中的"主副本"，生产者以及消费者只与 Leader 交互。
+ Follower ：每个分区的多个副本中的"从副本"，负责实时从 Leader 中同步数据，保持和 Leader 数据的同步。Leader 发生故障时，从 Follower 副本中重新选举新的 Leader 副本对外提供服务。
+ zookeeper：负责leader、follower投票
+ AR==Replica, ISR就是紧跟Leader副本的副本，OSR就是落后Leader很多的副本。Leader会维护哪些是ISR、哪些是OSR，OSR是可能追上ISR的。选Leader的时候优先从ISR里选。

## 生产者发送消息模式
+ 发后即忘：发了就不管了，不管Kafka有没有收到
+ 同步：发了一条，等待成功写入的消息，之后再发下一条 
+ 异步：发了一条，就继续发或者干别的，不会阻塞，是否成功可以回头查看日志

## 分区策略
+ 轮询：默认情况是轮着用，比较均衡。消费时无法保证消息有序
+ 用key指定分区：是根据key进行hash的，同一key会hash到同一分区。这样可以保证同一key的有序性
+ 自定义分区策略或者直接指定partition号

## Kafka 支持读写分离吗？为什么？
+ 不支持
+ 读写分离是指用不同的实例(进程/线程)提供读服务和写服务
+ 要是读和写是在不同的实例，那需要同步，带来数据一致性的麻烦
+ 同步需要耗时，带来数据延迟的麻烦

## 怎么负载均衡、扩容
+ 把分区均匀分到不同机器上。但实际问题还是有的，严重的话可能手动搬移
```
1.broker 端分配不均:当创建 topic 的时候可能会出现某些 broker 分配到的分区数多，而有些 broker 分配的分区少，这就导致了 leader 多副本不均。
2.生产者写入消息不均:生产者可能只对某些 broker 中的 leader 副本进行大量的写入操作，而对其他的 leader 副本不闻不问。
3.消费者消费不均:消费者可能只对某些 broker 中的 leader 副本进行大量的拉取操作，而对其他的 leader 副本不闻不问。
4.leader 副本切换不均：当主从副本切换或者分区副本进行了重分配后，可能会导致各个 broker 中的 leader 副本分配不均匀。
```
+ 增加分区数量
> 思考：增加分区数量可能要通知下游业务的消费组更改线程数量。不然可能分配不均

## 可靠性怎么保证
+ acks：该参数决定需要几个副本写入才能表示成功写入
+ 消息发送：“同步”方式可以保证，“异步”方式如果发现错误需要重传
+ 手动提交offset: 比如Flink消费时的checkpoint时会提交一次offset，从而之后可以从这个offset开始消费

## 分区再分配
+ 为了重新负载均衡
+ broker减少时
+ broker增多时

## 分区数越多越好吗？吞吐量就会越高吗？
+ 在一定条件下，分区数的数量是和吞吐量成正比的，分区数和性能也是成正比的。
> 横向扩容能力
+ 客户端/服务器端需要使用的内存就越多
+ 文件句柄的开销
+ 越多的分区可能增加端对端的延迟
+ 降低高可用性

## 如何增强消费者的消费能力？
+ 增加分区数
+ 增多消费者(开多线程)，但是最多增加到分区数。Flink的消费者分配策略是可以配置的，如RoundRobin 

## Kafka控制器
+ 就是利用zookeeper选举出一个管理其他broker的controller，称为控制器
+ 应该是Paxos算法。其他算法有Raft

## Kafka 为什么快
+ 顺序读写：每个分区内都是从头读到尾的
+ 零拷贝技术：直接将数据从**内核空间的读缓冲区**直接拷贝到**内核空间的 socket 缓冲区**，避免用户空间和内核空间来回转换
> 当然，别的MQ也会这样搞的
+ Page Cache：是直接调用的操作系统的Page Cache
+ 分区分段+索引
+ 批量操作：批量读写、批量压缩

## Kafka 什么时候会丢数据
+ 生产时，ack不够多
+ broker上 page cache 断电丢失
+ 消费时不开启 auto_commit，不告诉kafka现在消费到哪里了；或者告诉了错误的数值。



